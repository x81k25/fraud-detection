{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classification\n",
    "\n",
    "The purpose of this notebook is to assess different classification techniques with the credit card fraud data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve, precision_recall_curve, auc, recall_score, precision_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from time import perf_counter\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v23</th>\n",
       "      <th>v24</th>\n",
       "      <th>v25</th>\n",
       "      <th>v26</th>\n",
       "      <th>v27</th>\n",
       "      <th>v28</th>\n",
       "      <th>minute</th>\n",
       "      <th>hour</th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.783274</td>\n",
       "      <td>-1.996583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.269825</td>\n",
       "      <td>-1.996583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.983721</td>\n",
       "      <td>-1.996562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.418291</td>\n",
       "      <td>-1.996562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.670579</td>\n",
       "      <td>-1.996541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>False</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834784</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>59</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.296653</td>\n",
       "      <td>1.641931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>False</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>59</td>\n",
       "      <td>23</td>\n",
       "      <td>0.038986</td>\n",
       "      <td>1.641952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>False</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>59</td>\n",
       "      <td>23</td>\n",
       "      <td>0.641095</td>\n",
       "      <td>1.641974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>False</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>59</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.167680</td>\n",
       "      <td>1.641974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>False</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>59</td>\n",
       "      <td>23</td>\n",
       "      <td>2.724796</td>\n",
       "      <td>1.642058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        class         v1         v2        v3        v4        v5        v6  \\\n",
       "0       False  -1.359807  -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1       False   1.191857   0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2       False  -1.358354  -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3       False  -0.966272  -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4       False  -1.158233   0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "...       ...        ...        ...       ...       ...       ...       ...   \n",
       "284802  False -11.881118  10.071785 -9.834784 -2.066656 -5.364473 -2.606837   \n",
       "284803  False  -0.732789  -0.055080  2.035030 -0.738589  0.868229  1.058415   \n",
       "284804  False   1.919565  -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n",
       "284805  False  -0.240440   0.530483  0.702510  0.689799 -0.377961  0.623708   \n",
       "284806  False  -0.533413  -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n",
       "\n",
       "              v7        v8        v9  ...       v23       v24       v25  \\\n",
       "0       0.239599  0.098698  0.363787  ... -0.110474  0.066928  0.128539   \n",
       "1      -0.078803  0.085102 -0.255425  ...  0.101288 -0.339846  0.167170   \n",
       "2       0.791461  0.247676 -1.514654  ...  0.909412 -0.689281 -0.327642   \n",
       "3       0.237609  0.377436 -1.387024  ... -0.190321 -1.175575  0.647376   \n",
       "4       0.592941 -0.270533  0.817739  ... -0.137458  0.141267 -0.206010   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "284802 -4.918215  7.305334  1.914428  ...  1.014480 -0.509348  1.436807   \n",
       "284803  0.024330  0.294869  0.584800  ...  0.012463 -1.016226 -0.606624   \n",
       "284804 -0.296827  0.708417  0.432454  ... -0.037501  0.640134  0.265745   \n",
       "284805 -0.686180  0.679145  0.392087  ... -0.163298  0.123205 -0.569159   \n",
       "284806  1.577006 -0.414650  0.486180  ...  0.376777  0.008797 -0.473649   \n",
       "\n",
       "             v26       v27       v28  minute  hour  scaled_amount  \\\n",
       "0      -0.189115  0.133558 -0.021053       0     0       1.783274   \n",
       "1       0.125895 -0.008983  0.014724       0     0      -0.269825   \n",
       "2      -0.139097 -0.055353 -0.059752       0     0       4.983721   \n",
       "3      -0.221929  0.062723  0.061458       0     0       1.418291   \n",
       "4       0.502292  0.219422  0.215153       0     0       0.670579   \n",
       "...          ...       ...       ...     ...   ...            ...   \n",
       "284802  0.250034  0.943651  0.823731      59    23      -0.296653   \n",
       "284803 -0.395255  0.068472 -0.053527      59    23       0.038986   \n",
       "284804 -0.087371  0.004455 -0.026561      59    23       0.641095   \n",
       "284805  0.546668  0.108821  0.104533      59    23      -0.167680   \n",
       "284806 -0.818267 -0.002415  0.013649      59    23       2.724796   \n",
       "\n",
       "        scaled_seconds  \n",
       "0            -1.996583  \n",
       "1            -1.996583  \n",
       "2            -1.996562  \n",
       "3            -1.996562  \n",
       "4            -1.996541  \n",
       "...                ...  \n",
       "284802        1.641931  \n",
       "284803        1.641952  \n",
       "284804        1.641974  \n",
       "284805        1.641974  \n",
       "284806        1.642058  \n",
       "\n",
       "[284807 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cc = pd.read_parquet('../data/creditcard2.parquet')\n",
    "\n",
    "display(cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation metrics\n",
    "\n",
    "The most important peice of information when deciding on evaluation criteria is going to be the massive class imablance. As stated in the Kaggle description of the dataset itself, the best single metric for evaluating a classifier analyzing a highly imbalanced data set will be the Area Under the Precision-Recall Curve. ROC-AUC, R<sup>2</sup>, F1 score, and most other standard metrics for model evaluation will be less useful here; because if our model was to just spit at a negative class for every element it would still have very high levels of performance by all of these metrics. \n",
    "\n",
    "What we really need to emphasize is the Recall (also known as True Positive Rate) of the model. Our goal will be to maximize the true postivie results and minimize the false negative. For the sake of making it quantifiable, lets just say that a false neatgive will cost 4 times as much as a false positive. For these reasons, we will focus on the PR-AUC because it focus on the postive class performane, penalizes false positives and negatives more appropriately, and is less biased towards the majority class. We will still collect and observe and other model metrics, but they will be given very little weight in our overall selection of an ideal model. \n",
    "\n",
    "The other major metric I beleive is significant here is the exeuction time of the model. Transactional data sets like these can often be millions of rows and if one model offers a massive increase in compute efficiency, even if it comes at a small loss to model perfromance, than it may be the most practical overall pick for real world applications. I'm not going to quantify it here, but let's see what we end up with when we make our final consideration and recommendations.\n",
    "\n",
    "To summarise, model performanc will be determine by:\n",
    "1. PR-AUC, Recall\n",
    "2. Execution Time\n",
    "3. ROC-AUC, R<sup>2</sup>, F1 Score, Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty data frame to store model results\n",
    "model_performance_results = pd.DataFrame(columns=['pr_auc', 'recall', 'execution_time', 'roc_auc', 'R_squared', 'f1', 'precision'])\n",
    "\n",
    "# initialize model index counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## over-sampling and under-sampling\n",
    "\n",
    "Now that we have our features selected and refined at an indivual field level, let's look at techinques to deal with the massive class imblance of the data. For this analysis I am going to test 2 different techniques to try and mitigate this issue:\n",
    "\n",
    "### over-sampling with SMOTE\n",
    "\n",
    "We are going to sue the python imbalanced-learn library to perform an over-sampling over the dataset. We will be using the Synthetic Minority Over-sampling Technique (SMOTE) to generate more samples of the positive class to use for model training.\n",
    "\n",
    "### random under-samping\n",
    "\n",
    "For our under-sampling method, we are going to equalize the number of positive and negative class elements in our models. To do this we will train our models with all of the positive class data and randomly select and equal number of negative class elements. This will mean throwing out >99% of the data. Normally, that is not something you would want to do. So why do we want to try it? Because it might maxmize the performance metrics we actually care about. If the under-sampling ends up having a massively negative impact on our true negative rate, this will become readily apparent in our analysis and we may end up disqualifying this techinque from our final model selection.\n",
    "\n",
    "I am going to go ahead and create all of our training and test sets here, both to improve consistentcy between models, and because you should never write code twice that can be written once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break off target from features\n",
    "X = cc.drop('class', axis=1).values  # Features\n",
    "y = cc['class'].values  # Target\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# apply SMOTE to over sample\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_over, y_train_over = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# apply undersamping to balance the data\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_under, y_train_under = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run model\n",
    "\n",
    "Function to run the invidivual models. All objects, and the models functions will be passed to this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(\n",
    "    model_name,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    model_function,\n",
    "    model_parameters={}\n",
    "):  \n",
    "    # save the model name into the results data frame\n",
    "    model_index = 0\n",
    "    \n",
    "    start_time = perf_counter()\n",
    "\n",
    "    model = model_function(**model_parameters)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    end_time = perf_counter()\n",
    "\n",
    "    # calculate the exectution time and save to the results data frame\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    # save results to results data frame\n",
    "    model_performance_results.loc[model_index, 'model_name'] = model_name\n",
    "    model_performance_results.loc[model_index, 'execution_time'] = execution_time\n",
    "\n",
    "    # create output object\n",
    "    model_output = {\n",
    "        'model_name': model_name,\n",
    "        'model': model,\n",
    "        'model_index': model_index,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba,\n",
    "        'execution_time': execution_time,\n",
    "    }\n",
    "\n",
    "    return model_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate performance metrics\n",
    "\n",
    "I am going to add a function here to do all of my plotting and performanc metric calcuations, because repeatable code can be used to do it for each of the models I am using below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(\n",
    "    model_output,\n",
    "    y_test\n",
    "    #model, \n",
    "    #X_test, \n",
    "):\n",
    "    y_pred = model_output['y_pred']\n",
    "    y_pred_proba = model_output['y_pred_proba']\n",
    "\n",
    "    pass\n",
    "    # get the pr-auc score\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    pr_auc = auc(recall, precision)\n",
    "\n",
    "    # get model recall\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    # get roc auc score\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    # get f1 statistic\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    # get r-squared\n",
    "    R_squared = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # get model precision\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "\n",
    "    # create a 1 row dataframe to store the results\n",
    "    model_name = model_output['model_name']\n",
    "    model_performance_results = pd.DataFrame(columns=['pr_auc', 'recall', 'roc_auc', 'R_squared', 'f1', 'precision'])\n",
    "    model_performance_results.loc[model_name, 'pr_auc'] = pr_auc\n",
    "    model_performance_results.loc[model_name, 'recall'] = recall\n",
    "    model_performance_results.loc[model_name, 'execution_time'] = model_output['execution_time']\n",
    "    model_performance_results.loc[model_name, 'roc_auc'] = roc_auc\n",
    "    model_performance_results.loc[model_name, 'R_squared'] = R_squared\n",
    "    model_performance_results.loc[model_name, 'f1'] = f1\n",
    "    model_performance_results.loc[model_name, 'precision'] = precision\n",
    "\n",
    "    return model_performance_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize perfromance results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_performance(\n",
    "    model_output, \n",
    "    X_test,\n",
    "    y_test\n",
    "):  \n",
    "    # get recal and precision for prc plot\n",
    "    y_pred_proba = model_output['y_pred_proba']\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "\n",
    "    # Create a figure with two subplots side by side\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    # Plot Precision-Recall curve\n",
    "    axes[0].plot(recall, precision, marker='.')\n",
    "    axes[0].set_xlabel('Recall')\n",
    "    axes[0].set_ylabel('Precision')\n",
    "    axes[0].set_title('Precision-Recall Curve')\n",
    "\n",
    "    # Visualize the confusion matrix\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=['Predicted Negative', 'Predicted Positive'],\n",
    "                yticklabels=['Actual Negative', 'Actual Positive'], ax=axes[1])\n",
    "    axes[1].set_xlabel('Predicted Label')\n",
    "    axes[1].set_ylabel('Actual Label')\n",
    "    axes[1].set_title('Confusion Matrix')\n",
    "\n",
    "    # Adjust layout and add margin between plots\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.4)  # Adjust the wspace parameter to add margin\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # plot the ROC curve\n",
    "    #y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "    #fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "    #plt.plot(fpr, tpr)\n",
    "    #plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    #plt.xlabel('False Positive Rate')\n",
    "    #plt.ylabel('True Positive Rate')\n",
    "    #plt.title('ROC curve')\n",
    "    #plt.show()\n",
    "\n",
    "    return model_performance_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic regression\n",
    "\n",
    "simple logistic regression from the sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oversampling exeuction time:  8.481128999992507\n"
     ]
    }
   ],
   "source": [
    "# logistic regression with over sampled data\n",
    "# note: with the over sampled data the max iterations had to be increased for the logistic regression to converge\n",
    "model_name = \"logistic-regression-over\"\n",
    "\n",
    "log_over_output = train_test_model(\n",
    "    model_name = model_name,\n",
    "    X_train = X_train_over,\n",
    "    y_train = y_train_over,\n",
    "    X_test = X_test,\n",
    "    model_function = LogisticRegression,\n",
    "    model_parameters={'max_iter': 1000}\n",
    ")\n",
    "\n",
    "# create an empty row in the data from model results with the model name is it's index\n",
    "model_performance_results.loc[model_name, 'execution_time'] = log_over_output[\"execution_time\"] \n",
    "\n",
    "# print exeuction time\n",
    "print(\"oversampling exeuction time:  \" + str(log_over_output[\"execution_time\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undersampling exeuction time: 0.04193469999881927\n"
     ]
    }
   ],
   "source": [
    "# logistic regression with under sampled data\n",
    "# note: under sampled data also required an increase in max iterations for the logistic regression to converge\n",
    "model_name = \"logistic-regression-under\"\n",
    "\n",
    "log_under_output = train_test_model(\n",
    "    model_name = model_name,\n",
    "    X_train = X_train_under,\n",
    "    y_train = y_train_under,\n",
    "    X_test = X_test,\n",
    "    model_function = LogisticRegression,\n",
    "    model_parameters={'max_iter': 1000}\n",
    ")\n",
    "\n",
    "# create an empty row in the data from model results with the model name is it's index\n",
    "model_performance_results.loc[model_name, 'execution_time'] = log_over_output[\"execution_time\"]\n",
    "\n",
    "# print exeuction time\n",
    "print(\"undersampling exeuction time: \" + str(log_under_output[\"execution_time\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate and display model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>recall</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>R_squared</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041935</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logistic-regression-under</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic-regression-over</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.481129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic-regression-under</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.481129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic-regression-over</th>\n",
       "      <td>0.778539</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>8.481129</td>\n",
       "      <td>0.946284</td>\n",
       "      <td>0.974106</td>\n",
       "      <td>0.108761</td>\n",
       "      <td>0.057803</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic-regression-over</th>\n",
       "      <td>0.778539</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>8.481129</td>\n",
       "      <td>0.946284</td>\n",
       "      <td>0.974106</td>\n",
       "      <td>0.108761</td>\n",
       "      <td>0.057803</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic-regression-under</th>\n",
       "      <td>0.725327</td>\n",
       "      <td>0.908163</td>\n",
       "      <td>0.041935</td>\n",
       "      <td>0.935441</td>\n",
       "      <td>0.962624</td>\n",
       "      <td>0.077156</td>\n",
       "      <td>0.04029</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic-regression-over</th>\n",
       "      <td>0.778539</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>8.481129</td>\n",
       "      <td>0.946284</td>\n",
       "      <td>0.974106</td>\n",
       "      <td>0.108761</td>\n",
       "      <td>0.057803</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic-regression-under</th>\n",
       "      <td>0.725327</td>\n",
       "      <td>0.908163</td>\n",
       "      <td>0.041935</td>\n",
       "      <td>0.935441</td>\n",
       "      <td>0.962624</td>\n",
       "      <td>0.077156</td>\n",
       "      <td>0.04029</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             pr_auc    recall execution_time   roc_auc  \\\n",
       "0                               NaN       NaN       0.041935       NaN   \n",
       "logistic-regression-over        NaN       NaN       8.481129       NaN   \n",
       "logistic-regression-under       NaN       NaN       8.481129       NaN   \n",
       "logistic-regression-over   0.778539  0.918367       8.481129  0.946284   \n",
       "logistic-regression-over   0.778539  0.918367       8.481129  0.946284   \n",
       "logistic-regression-under  0.725327  0.908163       0.041935  0.935441   \n",
       "logistic-regression-over   0.778539  0.918367       8.481129  0.946284   \n",
       "logistic-regression-under  0.725327  0.908163       0.041935  0.935441   \n",
       "\n",
       "                          R_squared        f1 precision  \\\n",
       "0                               NaN       NaN       NaN   \n",
       "logistic-regression-over        NaN       NaN       NaN   \n",
       "logistic-regression-under       NaN       NaN       NaN   \n",
       "logistic-regression-over   0.974106  0.108761  0.057803   \n",
       "logistic-regression-over   0.974106  0.108761  0.057803   \n",
       "logistic-regression-under  0.962624  0.077156   0.04029   \n",
       "logistic-regression-over   0.974106  0.108761  0.057803   \n",
       "logistic-regression-under  0.962624  0.077156   0.04029   \n",
       "\n",
       "                                          model_name  \n",
       "0                          logistic-regression-under  \n",
       "logistic-regression-over                         NaN  \n",
       "logistic-regression-under                        NaN  \n",
       "logistic-regression-over                         NaN  \n",
       "logistic-regression-over                         NaN  \n",
       "logistic-regression-under                        NaN  \n",
       "logistic-regression-over                         NaN  \n",
       "logistic-regression-under                        NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate and store model metrics for the over sample logisti\n",
    "model_performance_results = pd.concat([\n",
    "    model_performance_results,\n",
    "    calculate_metrics(\n",
    "        model_output = log_over_output\n",
    "        ,y_test = y_test\n",
    "    )\n",
    "])\n",
    "\n",
    "# calculate and store model metrics for the under sample logistic\n",
    "model_performance_results = pd.concat([\n",
    "    model_performance_results,\n",
    "    calculate_metrics(\n",
    "        model_output = log_under_output\n",
    "        ,y_test = y_test\n",
    "    )\n",
    "])\n",
    "\n",
    "display(model_performance_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize performance for the over sampled logistic regression\n",
    "visualize_performance(\n",
    "    model_output = log_over_output,\n",
    "    X_test=X_test, \n",
    "    y_test=y_test\n",
    ")\n",
    "\n",
    "# visualize perfromance for the under sampled logistic regression\n",
    "visualize_performance(\n",
    "    model_output = log_under_output,\n",
    "    X_test=X_test, \n",
    "    y_test=y_test, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression with over sampled data\n",
    "rf_over_output = train_test_model(\n",
    "    model_index = 2,\n",
    "    model_name = \"random forest over\",\n",
    "    X_train = X_train_over,\n",
    "    y_train = y_train_over,\n",
    "    X_test = X_test,\n",
    "    model_function = RandomForestClassifier,\n",
    "    model_parameters={}\n",
    ")\n",
    "\n",
    "print(\"oversampling exeuction time:  \" + str(rf_over_output[\"execution_time\"]))\n",
    "\n",
    "# logistic regression with under sampled data\n",
    "rf_under_output = train_test_model(\n",
    "    model_index = 3,\n",
    "    model_name = \"random forest under\",\n",
    "    X_train = X_train_under,\n",
    "    y_train = y_train_under,\n",
    "    X_test = X_test,\n",
    "    model_function = RandomForestClassifier,\n",
    "    model_parameters={}\n",
    ")\n",
    "\n",
    "print(\"undersampling exeuction time: \" + str(rf_under_output[\"execution_time\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results for randome forest with over sampled data\n",
    "display_record_performance(\n",
    "    model_index=rf_over_output['model_index'], \n",
    "    model=rf_over_output['model'], \n",
    "    X_test=X_test, \n",
    "    y_test=y_test, \n",
    "    y_pred=rf_over_output['y_pred'], \n",
    "    y_pred_proba=rf_over_output['y_pred_proba']\n",
    ")\n",
    "\n",
    "# display results for random forest with under sampled data\n",
    "display_record_performance(\n",
    "    model_index=rf_under_output['model_index'], \n",
    "    model=rf_under_output['model'], \n",
    "    X_test=X_test, \n",
    "    y_test=y_test, \n",
    "    y_pred=rf_under_output['y_pred'], \n",
    "    y_pred_proba=rf_under_output['y_pred_proba']\n",
    ")\n",
    "\n",
    "display(model_performance_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost with over sampled data\n",
    "xgb_over_output = train_test_model(\n",
    "    model_index = 4,\n",
    "    model_name = \"xgboost over\",\n",
    "    X_train = X_train_over,\n",
    "    y_train = y_train_over,\n",
    "    X_test = X_test,\n",
    "    model_function = xgb.XGBClassifier,\n",
    "    model_parameters={'eval_metric':'mlogloss'}\n",
    ")\n",
    "\n",
    "print(\"oversampling exeuction time:  \" + str(xgb_over_output[\"execution_time\"]))\n",
    "\n",
    "\n",
    "# logistic regression with under sampled data\n",
    "xgb_under_output = train_test_model(\n",
    "    model_index = 5,\n",
    "    model_name = \"xgboost under\",\n",
    "    X_train = X_train_under,\n",
    "    y_train = y_train_under,\n",
    "    X_test = X_test,\n",
    "    model_function = xgb.XGBClassifier,\n",
    "    model_parameters={'eval_metric':'mlogloss'}\n",
    ")\n",
    "\n",
    "print(\"undersampling exeuction time: \" + str(xgb_under_output[\"execution_time\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results for xgboost with over sampled data\n",
    "display_record_performance(\n",
    "    model_index=xgb_over_output['model_index'], \n",
    "    model=xgb_over_output['model'], \n",
    "    X_test=X_test, \n",
    "    y_test=y_test, \n",
    "    y_pred=xgb_over_output['y_pred'], \n",
    "    y_pred_proba=xgb_over_output['y_pred_proba']\n",
    ")\n",
    "\n",
    "# display results for xgboost with under sampled data\n",
    "display_record_performance(\n",
    "    model_index=xgb_under_output['model_index'], \n",
    "    model=xgb_under_output['model'], \n",
    "    X_test=X_test, \n",
    "    y_test=y_test, \n",
    "    y_pred=xgb_under_output['y_pred'], \n",
    "    y_pred_proba=xgb_under_output['y_pred_proba']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost with scaled weights\n",
    "\n",
    "There is one additional option I want to modify here within the xgboost model. The xgboost model specifically offers an argument to scale easily scale the positve weight of the values of the target class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate scale_pos_weight\n",
    "neg_count = sum(y_train == 0)\n",
    "pos_count = sum(y_train == 1)\n",
    "scale_pos_weight = neg_count / pos_count\n",
    "\n",
    "# xgboost with over sampled data\n",
    "xgb_weighted_over_output = train_test_model(\n",
    "    model_index = 5,\n",
    "    model_name = \"xgboost weighted over\",\n",
    "    X_train = X_train_over,\n",
    "    y_train = y_train_over,\n",
    "    X_test = X_test,\n",
    "    model_function = xgb.XGBClassifier,\n",
    "    model_parameters={'eval_metric':'mlogloss', 'scale_pos_weight': scale_pos_weight}\n",
    ")\n",
    "\n",
    "print(\"oversampling exeuction time:  \" + str(xgb_weighted_over_output[\"execution_time\"]))\n",
    "\n",
    "# logistic regression with under sampled data\n",
    "xgb_weighted_under_output = train_test_model(\n",
    "    model_index = 6,\n",
    "    model_name = \"xgboost weighted under\",\n",
    "    X_train = X_train_under,\n",
    "    y_train = y_train_under,\n",
    "    X_test = X_test,\n",
    "    model_function = xgb.XGBClassifier,\n",
    "    model_parameters={'eval_metric':'mlogloss', 'scale_pos_weight': scale_pos_weight}\n",
    ")\n",
    "\n",
    "print(\"undersampling exeuction time: \" + str(xgb_weighted_under_output[\"execution_time\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dispaly model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results for xgboost weighted with over sampled data\n",
    "display_record_performance(\n",
    "    model_index=xgb_weighted_over_output['model_index'], \n",
    "    model=xgb_weighted_over_output['model'], \n",
    "    X_test=X_test, \n",
    "    y_test=y_test, \n",
    "    y_pred=xgb_weighted_over_output['y_pred'], \n",
    "    y_pred_proba=xgb_weighted_over_output['y_pred_proba']\n",
    ")\n",
    "\n",
    "# display results for xgboost weighted with under sampled data\n",
    "display_record_performance(\n",
    "    model_index=xgb_weighted_under_output['model_index'], \n",
    "    model=xgb_weighted_under_output['model'], \n",
    "    X_test=X_test, \n",
    "    y_test=y_test, \n",
    "    y_pred=xgb_weighted_under_output['y_pred'], \n",
    "    y_pred_proba=xgb_weighted_under_output['y_pred_proba']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## best candidate model\n",
    "\n",
    "Let's review the final scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(model_performance_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## next steps\n",
    "\n",
    "In this section I am going to address what next steps I would take, if this were a project I was conducted at my own place of work.\n",
    "\n",
    "### data pre-processing\n",
    "\n",
    "The first thing I would do if I was with an organziation that controlled the raw data, would be to try different steps in the pre-processing the raw data. Steps I would take when working with the raw data would include:\n",
    "\n",
    "- personally reviewing the quality of the dat\n",
    "- examining different options for feature generation on the raw data set\n",
    "- incorporating additional data, potentially including publically avaialable 3rd party data sets\n",
    "- trying different dimensionality reduction techniques, specifically UMAP, which I have found to be useful for transactional data in the past\n",
    "\n",
    "### other models I would like to test\n",
    "\n",
    "There were additional models I would like to test that are not currently in this project. Including:\n",
    "\n",
    "- supervised classification methods\n",
    "    - support vector machines\n",
    "    - neural networks\n",
    "        - specfically I would like to try a multi-layered perceptron, which I think would do well with an imbalanced data set\n",
    "- anaomly detction models\n",
    "\n",
    "### other methods to handle the imbalance in the data set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
